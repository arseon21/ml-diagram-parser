1. Описание архитектуры сервиса 
Общая архитектура решения представляет собой пайплайн для мультимодальной 
обработки изображений диаграмм. Система решает две задачи: 
1)  Прямая задача: изображение → текстовое описание алгоритма 
2)  Обратная задача: текстовое описание → изображение диаграммы (через mermaid) 
Основные компоненты системы: 
- UI: Streamlit 
- API: FastAPI  
- Препроцессинг: Pillow  
- Модуль Retrieval: CLIP (clip-ViT-B-32)  
- ML-модель: Qwen2.5-VL-3B-Instruct  
- Постпроцессинг: форматирование вывода модели в структурированное 
текстовое описание. Для обратной задачи – генерация и рендеринг mermaid-кода 
Поток данных (Прямая задача): 
1)  Вход: пользователь загружает изображение диаграммы (BPMN или блок-схема) в 
форматах PNG/JPG 
2)  Обработка: 
- Изображение проходит через предобработку  
- Изображение подаётся в модуль Retrieval (CLIP) для получения эмбеддинга 
- По эмбеддингу выполняется поиск ближайших примеров в train-датасете   
- Найденные примеры (текстовые описания) используются как контекст для 
VLM 
- Изображение и примеры подаются в квантованную модель Qwen2.5-VL с 
системным промптом 
3)  Выход: пользователю возвращается структурированное текстовое описание 
изображенного процесса 
Поток данных (Обратная задача): 
1)  Вход: пользователь вводит текстовое описание алгоритма 
2)  Обработка: описание подается в модель Qwen2.5-VL с промптом на генерацию 
mermaid-кода 
3)  Выход: сервис возвращает сгенерированный mermaid-код, который затем 
визуализируется в итоговое изображение png 
Развертывание: 
- Сервис разворачивается в Docker-контейнере с поддержкой NVIDIA CUDA 
- Требуемые ресурсы: GPU с объемом видеопамяти от 8 ГБ 
2. Технологический стек 
- Python 3.12.3 – основной стандарт для ML-разработки 
- FastAPI – выбран за высокую производительность и встроенную поддержку 
асинхронности 
- ML-библиотеки: Transformers, Bitsandbytes, Accelerate – стандартный стек для 
запуска современных VLM с использованием квантования 
- Модель Retrieval – легковесная, но эффективная модель для получения 
семантических эмбеддингов изображений 
- Модель Qwen2.5-VL-3B-Instruct – современная SOTA модель с открытыми 
весами, оптимизированная под инференс и поддерживающая инструменты. 3B 
параметров в квантованном виде помещаются в 8 ГБ VRAM 
- REST API (JSON) – легкая интеграция фронтенда и бэкенда 
- Docker + NVIDIA Container Toolkit – обеспечение воспроизводимости среды 
 
3. План реализации (roadmap) 
1)  Анализ задачи и подготовка данных: сформировать набор тестовых диаграмм 
(BPMN, блок-схемы) и определены правила их перевода в mermaid 
2)  Выбор и первичная проверка модели: проверить модель Qwen2.5-VL, успешно 
ли запускается локально в 4-bit и выдает корректный mermaid-код на 2-3 тестовых 
примерах 
3)  Реализация базового пайплайна: скрипт автоматической обработки 
изображение -> Pillow -> Модель -> mermaid-текст 
4)  Оборачивание в API: реализовать сервис на FastAPI, принимающий файлы и 
выдающий результат 
5)  Docker-сборка: реализовать готовый образ, запускаемый одной командой docker 
compose up 
6)  Улучшения и UI: простой интерфейс на Streamlit для демонстрации работы и 
обработка обратной задачи. Доработана обратная задача: отображение 
сгенерированной диаграммы (mermaid) непосредственно в интерфейсе 

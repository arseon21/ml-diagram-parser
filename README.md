__ИНСТРУКИЦЯ__

1. В файле model.py настроить максимально доступные под сервис значения VRAM и RAM
2. docker compose build
3. docker compose up

__ПРОЕКТ КОМАНДЫ SysCreators__
1. Описание архитектуры сервиса 
Общая архитектура решения представляет собой пайплайн для мультимодальной 
обработки изображений диаграмм. Система решает две задачи: 
1)  Прямая задача: изображение → текстовое описание алгоритма 
2)  Обратная задача: текстовое описание → изображение диаграммы (через mermaid) 

Основные компоненты системы: 
- UI: Streamlit 
- API: FastAPI  
- Препроцессинг: Pillow  
- Модуль Retrieval: CLIP (clip-ViT-B-32)  
- ML-модель: Qwen2.5-VL-3B-Instruct  
- Постпроцессинг: форматирование вывода модели в структурированное 
текстовое описание. Для обратной задачи – генерация и рендеринг mermaid-кода 

Поток данных (Прямая задача): 
1)  Вход: пользователь загружает изображение диаграммы (BPMN или блок-схема) в 
форматах PNG/JPG 
2)  Обработка: 
- Изображение проходит через предобработку  
- Изображение подаётся в модуль Retrieval (CLIP) для получения эмбеддинга 
- По эмбеддингу выполняется поиск ближайших примеров в train-датасете   
- Найденные примеры (текстовые описания) используются как контекст для 
VLM 
- Изображение и примеры подаются в квантованную модель Qwen2.5-VL с 
системным промптом 
3)  Выход: пользователю возвращается структурированное текстовое описание 
изображенного процесса 

Развертывание: 
- Сервис разворачивается в Docker-контейнере с поддержкой NVIDIA CUDA 
- Требуемые ресурсы: GPU с объемом видеопамяти от 8 ГБ 

2. Технологический стек 
- Python 3.12.3 – основной стандарт для ML-разработки 
- FastAPI – выбран за высокую производительность и встроенную поддержку 
асинхронности 
- ML-библиотеки: Transformers, Bitsandbytes, Accelerate – стандартный стек для 
запуска современных VLM с использованием квантования 
- Модель Retrieval – легковесная, но эффективная модель для получения 
семантических эмбеддингов изображений 
- Модель Qwen2.5-VL-3B-Instruct – современная SOTA модель с открытыми 
весами, оптимизированная под инференс и поддерживающая инструменты. 3B 
параметров в квантованном виде помещаются в 8 ГБ VRAM 
- REST API (JSON) – легкая интеграция фронтенда и бэкенда 
- Docker + NVIDIA Container Toolkit – обеспечение воспроизводимости среды 
 
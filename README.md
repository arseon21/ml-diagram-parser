1. Описание архитектуры сервиса
•UI: Streamlit
• API: FastAPI
• Препроцессинг: Pillow
• ML-модель: Qwen2.5-VL-3B-Instruct
• Постпроцессинг: конвертация структурированного текста в код Mermaid.js

Поток данных:
• Вход: иззображение диаграммы (BPMN или блок-схема) в форматах PNG/JPG.
• Обработка: изображение проходит через Pillow, затем подается в квантованную (4-
bit) модель Qwen2.5-VL с системным промптом. Модель генерирует детальное
текстовое описание.
Для обратной задачи: преобразование текстового файла в mermaid-код.
• Выход: текстовое описание архитектуры и сгенерированны код для обратной задачи.
• Сервис разворачивается в Docker-контейнере с поддержкой NVIDIA CUDA.
• Требуемые ресурсы: GPU с объемом видеопамяти от 8 ГБ.

2. Технологический стек
• Python 3.12.3 - основной стандарт для ML-разработки.
• FastAPI - выбран за высокую производительность и встроенную поддержку
асинхронности.
• ML-библиотеки: Transformers, Bitsandbytes, Accelerate - стандартный стек для
запуска современных VLM с использованием квантования.
• Модель Qwen2.5-VL-3B-Instruct - современная SOTA модель
• REST API (JSON) - легкая интеграция фронтенда и бэкенда.
• Docker + NVIDIA Container Toolkit - обеспечение воспроизводимости среды.

3. План реализации (roadmap)
1. Анализ задачи и подготовка данных:
• сформировать набор тестовых диаграмм (BPMN, блок-схемы) и определены правила
их перевода в текстовое описание.2. Выбор и первичная проверка модели:
• проверить модель Qwen2.5-VL, успешно ли запускается локально в 4-bit и выдает
корректное текстовое описание модели на 2-3 тестовых примерах.
3. Реализация базового пайплайна:
• скрипт автоматической обработки:
Изображение -> Pillow -> Модель -> Описание в файле txt.
4. Оборачивание в API:
• реализовать сервис на FastAPI, принимающий файлы и выдающий результат.
5. Docker-сборка:
• Реализовать готовый образ, запускаемый одной командой docker compose up.
6. Улучшения и UI (Опционально):
• простой интерфейс на Streamlit для демонстрации работы и обработка «обратной
задачи» .